import os
import glob
import cv2
import json
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision.transforms import Compose, ToTensor, Normalize
from super_gradients.training.utils import HpmStruct
from super_gradients import Trainer, init_trainer
from super_gradients.training import models
from super_gradients.training.losses import PPYoloELoss
from super_gradients.training.metrics import DetectionMetrics_050_095
from super_gradients.training.models.detection_models.pp_yolo_e import PPYoloEPostPredictionCallback

def resize_image(image, divisor=32):
    """
    Resizing the image to ensure each dimension is divisible by the specified divisor.
    """
    h, w, _ = image.shape
    new_h = h + (divisor - h % divisor) % divisor
    new_w = w + (divisor - w % divisor) % divisor
    resized_image = cv2.resize(image, (new_w, new_h))
    return resized_image

class PigDataset(Dataset):
    def __init__(self, root_dir, subset, transform=None):
        self.root_dir = os.path.join(root_dir, subset)
        self.transform = transform
        self.samples = self._load_samples()

    def _load_samples(self):
        samples = []
        for vid_dir in sorted(os.listdir(self.root_dir)):
            img_dir = os.path.join(self.root_dir, vid_dir, 'images')
            ann_dir = os.path.join(self.root_dir, vid_dir, 'annotations')
            ann_path = os.path.join(ann_dir, os.listdir(ann_dir)[0])  

            with open(ann_path) as f:
                annotations = json.load(f)["annotations"]

            for ann_entry in annotations:
                for frame, frame_ann in ann_entry["frames"].items():
                    img_name = f'{ann_path.split("/")[-1].split(".")[0]}.mp4_{frame}.jpg'
                    img_path = os.path.join(img_dir, img_name)
                    if os.path.exists(img_path):
                        samples.append((img_path, frame_ann))

        return samples

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        img_path, frame_ann = self.samples[idx]
        image = cv2.imread(img_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image = resize_image(image)

        if self.transform:
            image = self.transform(image)
        
        bbox = frame_ann["bounding_box"]
        boxes = torch.tensor([[bbox['x'], bbox['y'], bbox['x'] + bbox['w'], bbox['y'] + bbox['h']]])
        labels = torch.tensor([1])  

        target = {
            'boxes': boxes.float(),
            'labels': labels
        }
        
        return image, target
def main():
    transforms = Compose([
        ToTensor(),
        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    dataset_params = {
    'root_dir': '/home/user-1/pig_dataset',
    'classes': ['pig'] 
    }

    CHECKPOINT_DIR = '/home/user-1/det_output/'  
    trainer = Trainer(experiment_name='yolonas_run', ckpt_root_dir=CHECKPOINT_DIR)
    model = models.get('yolo_nas_l', num_classes=len(dataset_params['classes']), pretrained_weights="coco")

    training_params = {
    "max_epochs": 20,
    "silent_mode": False,
    "average_best_models": True,
    "warmup_mode": "linear_epoch_step",
    "warmup_initial_lr": 1e-6,
    "initial_lr": 5e-4,
    "lr_mode": "cosine",
    "cosine_final_lr_ratio": 0.1,
    "optimizer": "Adam",
    "optimizer_params": {"weight_decay": 0.0001},
    "zero_weight_decay_on_bias_and_bn": True,
    "ema": True,
    "ema_params": {"decay": 0.9, "decay_type": "threshold"},
    "mixed_precision": True,
    "loss": PPYoloELoss(use_static_assigner=False, num_classes=1, reg_max=16),
    "valid_metrics_list": [DetectionMetrics_050_095(score_thres=0.8, top_k_predictions=300, num_cls=1, normalize_targets=True, post_prediction_callback=PPYoloEPostPredictionCallback(score_threshold=0.01, nms_top_k=1000, max_predictions=300, nms_threshold=0.7))],
    "metric_to_watch": 'mAP@0.50:0.95'
}
    train_dataset = PigDataset(root_dir=dataset_params['root_dir'], subset='train', transform=transforms)
    val_dataset = PigDataset(root_dir=dataset_params['root_dir'], subset='val', transform=transforms)

    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)
    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)

    # Start training
    trainer.train(model=model, train_loader=train_loader, valid_loader=val_loader, training_params=training_params)
    trainer.train(model=model, 
                  train_loader=train_loader, 
                  valid_loader=val_loader, 
                  training_params=training_params)

if __name__ == "__main__":
    main()

